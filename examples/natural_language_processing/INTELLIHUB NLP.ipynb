{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106e9a6a",
   "metadata": {},
   "source": [
    "### Natural Language Processing using INTELLIHUB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bcb56d",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "INTELLIHUB's Natural Language Processing module provides below techniques to analyse text\n",
    "\n",
    "1. Sentiment Analysis\n",
    "2. Parts of Speech Tagging\n",
    "3. Named Entity Recognition\n",
    "4. Dependancy Parser\n",
    "5. Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9b95311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running this notebook on GOOGLE COLAB, uncomment below code & run this cell\n",
    "\n",
    "# !git clone https://github.com/Spotflock/intellihub-sdk-python.git\n",
    "# %cd intellihub-sdk-python/examples/natural_language_processing/\n",
    "# !pip install intellihub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9a0eb",
   "metadata": {},
   "source": [
    "#### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c66d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intellihub\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245e379",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4fa6b",
   "metadata": {},
   "source": [
    "> <u>Parameters Descriptions</u>\n",
    ">\n",
    "> **API key**: `If authentication is enabled`, you need to provide a valid API key\n",
    ">\n",
    "> **base_url**: url where kong/base service provided by INTELLIHUB is deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1096d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid API key (default=None) : ········\n",
      "Endpoint for IINTELLIHUB (default=http://localhost:5000) : https://prod-kong.intellihub.ai\n"
     ]
    }
   ],
   "source": [
    "api_key = getpass(\"Valid API key (default=None) : \") or None\n",
    "base_url = input(\"Endpoint for INTELLIHUB (default=http://localhost:5000) : \") or \"http://localhost:5000\"\n",
    "\n",
    "client = intellihub.IntellihubAiClient(api_key, base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8daaeb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>See Also:</b> \n",
    "\n",
    " \n",
    "\n",
    "1. [How to generate API key](https://docs.intellihub.ai/intellihub-sdk/docs/build/html/getting_started/generateAPIkey.html)\n",
    "2. [INTELLIHUB deployment](http://docs.intellihub.ai/intellihub-sdk/docs/build/html/getting_started/INTELLIHUB_setup.html)\n",
    "\n",
    " \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e36d966",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    ">Sentiment analysis (also known as opinion mining or emotion AI) is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine.~[wikipedia](https://en.wikipedia.org/wiki/Sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b56deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nltk_vader': {'emotion': 'POSITIVE',\n",
       "  'scores': {'compound': 0.4201,\n",
       "   'negative': 0.0,\n",
       "   'positive': 0.285,\n",
       "   'neutral': 0.715}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I really like the new design of your website\"\n",
    "\n",
    "intellihub_sentiment = client.sentiment_analysis(text)\n",
    "intellihub_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19598102",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>Caution:</b> Run below cell, only if <b>Supported AI Engine Credentials</b> are updated in INTELLIHUB configurations while installation </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a85955ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'azure': {'emotion': 'NEUTRAL',\n",
       "  'scores': {'positive': 0.19, 'neutral': 0.81, 'negative': 0.0}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure_sentiment = client.sentiment_analysis(text, sources=['azure'])\n",
    "azure_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c54c9",
   "metadata": {},
   "source": [
    "### Parts of Speech Tagging\n",
    "\n",
    ">In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech,[1] based on both its definition and its context. A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.~[wikipedia](https://en.wikipedia.org/wiki/Part-of-speech_tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54e09851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spacy': {'result': {'The': 'DT',\n",
       "   'old': 'JJ',\n",
       "   'tired': 'JJ',\n",
       "   'man': 'NN',\n",
       "   'was': 'VBD',\n",
       "   'sitting': 'VBG',\n",
       "   'under': 'IN',\n",
       "   'a': 'DT',\n",
       "   'tree': 'NN',\n",
       "   'and': 'CC',\n",
       "   'patiently': 'RB',\n",
       "   'waiting': 'VBG',\n",
       "   'for': 'IN',\n",
       "   'his': 'PRP$',\n",
       "   'son': 'NN',\n",
       "   'to': 'TO',\n",
       "   'arrive': 'VB'}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The old tired man was sitting under a tree and patiently waiting for his son to arrive\"\n",
    "\n",
    "intellihub_pos_tagger = client.pos_tagger(text)\n",
    "intellihub_pos_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51300e1f",
   "metadata": {},
   "source": [
    "### Named Entity Recognition\n",
    "\n",
    ">Named-entity recognition (NER) (also known as (named) entity identification, entity chunking, and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.~[wikipedia](https://en.wikipedia.org/wiki/Named-entity_recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25306d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spacy': {'result': {'Delhi': 'GPE',\n",
       "   '1.3': 'CARDINAL',\n",
       "   'Arvind Kejriwal': 'PERSON'}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Delhi has a population of 1.3 crore. Arvind Kejriwal is the Chief Minister of Delhi\"\n",
    "\n",
    "intellihub_ner_tagger = client.ner_tagger(text)\n",
    "intellihub_ner_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94289fba",
   "metadata": {},
   "source": [
    "### Dependency Parser\n",
    "\n",
    ">Dependency grammar (DG) is a class of modern grammatical theories that are all based on the dependency relation (as opposed to the constituency relation of phrase structure) and that can be traced back primarily to the work of Lucien Tesnière. Dependency is the notion that linguistic units, e.g. words, are connected to each other by directed links. The (finite) verb is taken to be the structural center of clause structure. All other syntactic units (words) are either directly or indirectly connected to the verb in terms of the directed links, which are called dependencies.~[wikipedia](https://en.wikipedia.org/wiki/Dependency_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd7d53dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Natural': {'dep': 'amod',\n",
       "  'headText': 'language',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': []},\n",
       " 'language': {'dep': 'compound',\n",
       "  'headText': 'data',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': ['natural']},\n",
       " 'processing': {'dep': 'nsubj',\n",
       "  'headText': 'is',\n",
       "  'headPOS': 'AUX',\n",
       "  'children': ['language']},\n",
       " 'is': {'dep': 'ROOT',\n",
       "  'headText': 'is',\n",
       "  'headPOS': 'AUX',\n",
       "  'children': ['processing', 'subfield', '.']},\n",
       " 'a': {'dep': 'det',\n",
       "  'headText': 'subfield',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': []},\n",
       " 'subfield': {'dep': 'attr',\n",
       "  'headText': 'is',\n",
       "  'headPOS': 'AUX',\n",
       "  'children': ['a', 'of', ',', 'program']},\n",
       " 'of': {'dep': 'prep',\n",
       "  'headText': 'amounts',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': ['data']},\n",
       " 'linguistics': {'dep': 'pobj',\n",
       "  'headText': 'of',\n",
       "  'headPOS': 'ADP',\n",
       "  'children': [',', 'science']},\n",
       " ',': {'dep': 'punct',\n",
       "  'headText': 'subfield',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': []},\n",
       " 'computer': {'dep': 'compound',\n",
       "  'headText': 'science',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': []},\n",
       " 'science': {'dep': 'conj',\n",
       "  'headText': 'linguistics',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': ['computer', ',', 'and', 'intelligence']},\n",
       " 'and': {'dep': 'cc',\n",
       "  'headText': 'process',\n",
       "  'headPOS': 'VERB',\n",
       "  'children': []},\n",
       " 'artificial': {'dep': 'amod',\n",
       "  'headText': 'intelligence',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': []},\n",
       " 'intelligence': {'dep': 'conj',\n",
       "  'headText': 'science',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': ['artificial', 'concerned']},\n",
       " 'concerned': {'dep': 'acl',\n",
       "  'headText': 'intelligence',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': ['with']},\n",
       " 'with': {'dep': 'prep',\n",
       "  'headText': 'concerned',\n",
       "  'headPOS': 'VERB',\n",
       "  'children': ['interactions']},\n",
       " 'the': {'dep': 'det',\n",
       "  'headText': 'interactions',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': []},\n",
       " 'interactions': {'dep': 'pobj',\n",
       "  'headText': 'with',\n",
       "  'headPOS': 'ADP',\n",
       "  'children': ['the', 'between']},\n",
       " 'between': {'dep': 'prep',\n",
       "  'headText': 'interactions',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': ['computers']},\n",
       " 'computers': {'dep': 'dobj',\n",
       "  'headText': 'program',\n",
       "  'headPOS': 'VERB',\n",
       "  'children': []},\n",
       " 'human': {'dep': 'amod',\n",
       "  'headText': 'language',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': []},\n",
       " 'in': {'dep': 'prep',\n",
       "  'headText': 'program',\n",
       "  'headPOS': 'VERB',\n",
       "  'children': ['particular']},\n",
       " 'particular': {'dep': 'amod',\n",
       "  'headText': 'in',\n",
       "  'headPOS': 'ADP',\n",
       "  'children': []},\n",
       " 'how': {'dep': 'advmod',\n",
       "  'headText': 'program',\n",
       "  'headPOS': 'VERB',\n",
       "  'children': []},\n",
       " 'to': {'dep': 'aux',\n",
       "  'headText': 'process',\n",
       "  'headPOS': 'VERB',\n",
       "  'children': []},\n",
       " 'program': {'dep': 'relcl',\n",
       "  'headText': 'subfield',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': ['in', 'how', 'to', 'computers', 'process']},\n",
       " 'process': {'dep': 'xcomp',\n",
       "  'headText': 'program',\n",
       "  'headPOS': 'VERB',\n",
       "  'children': ['to', 'and', 'analyze']},\n",
       " 'analyze': {'dep': 'conj',\n",
       "  'headText': 'process',\n",
       "  'headPOS': 'VERB',\n",
       "  'children': ['amounts']},\n",
       " 'large': {'dep': 'amod',\n",
       "  'headText': 'amounts',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': []},\n",
       " 'amounts': {'dep': 'dobj',\n",
       "  'headText': 'analyze',\n",
       "  'headPOS': 'VERB',\n",
       "  'children': ['large', 'of']},\n",
       " 'natural': {'dep': 'amod',\n",
       "  'headText': 'language',\n",
       "  'headPOS': 'NOUN',\n",
       "  'children': []},\n",
       " 'data': {'dep': 'pobj',\n",
       "  'headText': 'of',\n",
       "  'headPOS': 'ADP',\n",
       "  'children': ['language']},\n",
       " '.': {'dep': 'punct', 'headText': 'is', 'headPOS': 'AUX', 'children': []}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Natural language processing is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
    "\n",
    "intellihub_dependency_parser = client.dependency_parser(text)\n",
    "intellihub_dependency_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9feec4",
   "metadata": {},
   "source": [
    "### Tags Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2873f5b4",
   "metadata": {},
   "source": [
    ">Tags extraction is a textual information processing task concerned with the automatic extraction of representative and characteristic phrases from a document that express all the key aspects of its content. Extracts key words from a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80f9154b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rake': {'tags': ['artificial intelligence',\n",
       "   'intelligence demonstrated',\n",
       "   'machines',\n",
       "   'unlike',\n",
       "   'natural intelligence displayed',\n",
       "   'humans',\n",
       "   'animals',\n",
       "   'involves consciousness',\n",
       "   'emotionality']}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Artificial intelligence is intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals, which involves consciousness and emotionality.\"\n",
    "\n",
    "intellihub_tags = client.tags(text)\n",
    "intellihub_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5532b66f",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "For more detail on using NLP APIs please refer [INTELLIHUB NLP Documentation](https://docs.intellihub.ai/natural_language_processing/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f7dd8",
   "metadata": {},
   "source": [
    ":\n",
    "<center><b>For More Details about INTELLIHUB</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83300d5e",
   "metadata": {},
   "source": [
    "|[<img src=\"https://pbs.twimg.com/profile_images/909757546063323137/-RIWgodF.jpg\" width=50 title=\"Pypi Logo\"/>](https://pypi.org/project/intellihub/) |[<img src=\"https://cdn.iconscout.com/icon/free/png-512/documentation-1502741-1272951.png\" width=50 title=\"Documentation\"/>](https://docs.intellihub.ai) | [<img src=\"https://cdn4.iconfinder.com/data/icons/iconsimple-logotypes/512/github-512.png\" width=50 title=\"Documentation\"/>](https://docs.intellihub.ai)| \n",
    "|:-------------:|:-------:|:--------:|\n",
    "|pypi|Documentation|Github|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1f4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "dev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
